{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\viole\\Desktop\\SCHOOL\\AI\\housePrices\\train.csv\")\n",
    "test =  pd.read_csv(r\"C:\\Users\\viole\\Desktop\\SCHOOL\\AI\\housePrices\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removemos la columna ID porque no es util para el analisis\n",
    "train.drop('Id', axis = 1, inplace = True)\n",
    "print('Sin ID el train set es de dimension: {}' .format(train.shape))\n",
    "testID = test['Id']\n",
    "test.drop('Id', axis = 1, inplace = True)\n",
    "print('Sin ID el test set es de dimension: {}' .format(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizamos los datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col_train = [col for col in train.columns if train[col].isnull().any()]\n",
    "faltantes_train = ((train[col_train].isnull().sum()*100)/len(train)).round(3)\n",
    "faltantes_train = faltantes_train.sort_values(ascending = False)\n",
    "\n",
    "col_test = [col for col in test.columns if test[col].isnull().any()]\n",
    "faltantes_test = ((test[col_test].isnull().sum()*100)/len(test)).round(3)\n",
    "faltantes_test = faltantes_test.sort_values(ascending = False)\n",
    "\n",
    "combined = pd.concat((faltantes_train, faltantes_test), keys = ['train', 'test'], axis = 1)\n",
    "print(combined)\n",
    "\n",
    "combined.reset_index(inplace = True)\n",
    "combined= pd.melt(combined[:18], id_vars=['index'], value_vars=['train', 'test'],\n",
    "                         var_name = 'set', value_name = 'porcentaje')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualmente\n",
    "sns.set_style(\"dark\")\n",
    "fig, ax = plt.subplots(figsize = (14, 12))\n",
    "sns.barplot(x = combined['porcentaje'], y = combined['index'], hue = combined['set'], palette = ['lightcoral', 'plum'])\n",
    "plt.xlabel('Predictores', fontsize = 12)\n",
    "plt.ylabel('Porcentaje de datos faltantes', fontsize = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la descripción de los datos se indica que para Alley, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, FireplaceQu, GarageType, GarageFinish, GarageQual, GarageCond, PoolQC, Fence y MiscFeature la nomenclatura NA **no** indica un dato faltante sino la falta del feature en la propiedad (sin garage, sin piscina etc), así que sustituiremos NA por la categoría None. \n",
    "<p> La funcionalidad se asume típica, asi que sustituimos los faltantes por la categoría 'Typ'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2','FireplaceQu', \n",
    "            'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature'):\n",
    "            train[col] = train[col].fillna('None')\n",
    "            test[col] = test[col].fillna('None')\n",
    "            \n",
    "\n",
    "train['Functional'] = train['Functional'].fillna('Typ')\n",
    "test['Functional'] = test['Functional'].fillna('Typ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ocurrencias de NA son las mismas de MasVnrType y MasVnrArea  asumiremos que la propiedad no tiene esta estructura y por lo tanto el área de esta es 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('MasVnrType', 'MasVnrArea'):\n",
    "    train['MasVnrType'] = train['MasVnrType'].fillna('None')\n",
    "    train['MasVnrArea'] = train['MasVnrArea'].fillna(0)\n",
    "    test['MasVnrType'] = test['MasVnrType'].fillna('None')\n",
    "    test['MasVnrArea'] = test['MasVnrArea'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no hay garage entonces su área es 0 al igual que el número de carros; y si no hay sótano los predictores BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath que indican áreas y número de baños también son 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "        train[col] = train[col].fillna(0)\n",
    "        test[col] = test[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LotFrontage indica la longitud de la calle frente a la propiedad, así que sustituimos los faltantes con la mediana de esta longitud por vecindario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LotFrontage'] = train.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "test['LotFrontage'] = test.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los demás predictores categóricos sustituimos los faltantes con la categoría más común."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('Electrical', 'Exterior1st', 'Exterior2nd', 'KitchenQual', 'MSZoning', 'Utilities', 'SaleType'):\n",
    "    train[col] = train[col].fillna(train[col].mode()[0])\n",
    "    test[col] = test[col].fillna(test[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos si quedan faltantes\n",
    "col_train = [col for col in train.columns if train[col].isnull().any()]\n",
    "col_test = [col for col in test.columns if test[col].isnull().any()]\n",
    "print('En el trainset quedan {} '.format(len(col_train)),'columnas con datos faltantes.')\n",
    "print('En el testset quedan {} '.format(len(col_test)),'columnas con datos faltantes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos todo\n",
    "del col_train\n",
    "del col_test\n",
    "del faltantes_train\n",
    "del faltantes_test\n",
    "del combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlación y visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploramos la respuesta\n",
    "train.SalePrice.describe()\n",
    "print (\"SalePrice tiene sesgo: \", train.SalePrice.skew())\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "sns.distplot(train['SalePrice'], color = 'plum', kde = False)\n",
    "plt.xlabel('SalePrice', fontsize = 12)\n",
    "plt.ylabel('Frecuencia', fontsize = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la respuesta está sesgada hacia la derecha i.e. pocas personas pueden pagar propiedades muy costosas. Para corregir esto aplicaremos la transformación log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['logSalePrice'] = np.log(train['SalePrice']) \n",
    "print ('El sesgo es ahora: ', train.logSalePrice.skew())\n",
    "train.drop('SalePrice', axis = 1, inplace = True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 8))\n",
    "sns.distplot(train['logSalePrice'], color = 'plum', kde = False)\n",
    "plt.xlabel('logSalePrice', fontsize = 12)\n",
    "plt.ylabel('Frecuencia', fontsize = 12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlación entre los predictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train.corr(method = 'spearman')\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    fig, ax = plt.subplots(figsize = (24,18))\n",
    "    sns.heatmap(train.corr(), vmin = -1, vmax = 1, cmap='coolwarm', annot=True, mask = np.triu(corr_matrix), fmt = '.1g')\n",
    "\n",
    "# Predictores mas correlacionados entre si\n",
    "corr_matrix = corr_matrix.abs()\n",
    "most_corr = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "                  .stack()\n",
    "                  .sort_values(ascending=False))\n",
    "most_corr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train.corr(method = 'spearman')['logSalePrice'][:-1] \n",
    "imp_features = corr_matrix[abs(corr_matrix) > 0.5].sort_values(ascending=False)\n",
    "print(\"Hay {} predictores fuertemente correlacionados con logSalePrice:\\n{}\".format(len(imp_features), imp_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigamos la relacion de la respuesta con algunos de estos predictores\n",
    "train.OverallQual.unique()\n",
    "quality_pivot = train.pivot_table(index='OverallQual', values='logSalePrice', aggfunc = np.median)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "sns.barplot(x = quality_pivot.index, y = quality_pivot.logSalePrice, color = 'pink')\n",
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "sns.scatterplot(x = train['GrLivArea'], y = train['logSalePrice'], color = 'plum')\n",
    "\n",
    "cars_pivot = train.pivot_table(index='GarageCars', values='logSalePrice', aggfunc = np.median)\n",
    "fig, ax = plt.subplots(figsize = (10,8))\n",
    "sns.barplot(x = cars_pivot.index, y = cars_pivot.logSalePrice, color = 'lightsalmon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación de variables dummys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Primero aislamos las ordinales\n",
    "ordinals = ('Alley', 'BsmtCond', 'BsmtFinType2', 'BsmtFinType1', 'BsmtExposure', 'BsmtQual', \n",
    "            'CentralAir','ExterCond', 'ExterQual', 'Fence', 'FireplaceQu', 'Functional', 'GarageQual', \n",
    "            'GarageCond', 'HeatingQC', 'PoolQC', 'KitchenQual',  \n",
    "          'GarageFinish', 'LandSlope', 'LandContour',\n",
    "        'LotShape', 'PavedDrive', 'Street',  'MSSubClass', 'OverallCond')\n",
    "\n",
    "for col in ordinals:\n",
    "    label = LabelEncoder() \n",
    "    label.fit(list(train[col].values)) \n",
    "    train[col] = label.transform(list(train[col].values))\n",
    "    label = LabelEncoder()\n",
    "    label.fit(list(test[col].values)) \n",
    "    test[col] = label.transform(list(test[col].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = train.select_dtypes(include = 'object').columns #son las mismas en train & test\n",
    "\n",
    "train_y = train.logSalePrice.values\n",
    "train.drop('logSalePrice', axis = 1, inplace = True)\n",
    "\n",
    "train_objs_num = len(train)\n",
    "dataset = pd.concat(objs=[train, test], axis=0)\n",
    "dataset = pd.get_dummies(dataset, columns = dummy_cols, drop_first = True)\n",
    "train = dataset[:train_objs_num]\n",
    "test = dataset[train_objs_num:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos en training y test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train_y, random_state = 42, test_size = 0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui haremos cross validation para encontrar los hyperparámetros óptimos\n",
    "\n",
    "ridgecv = RidgeCV(alphas = np.linspace(0.01,10,30), normalize = True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "print('Alpha de Ridge : {}' .format(ridgecv.alpha_))\n",
    "\n",
    "lassocv = LassoCV(alphas = None, cv = 5, normalize = True)\n",
    "lassocv.fit(X_train, y_train)\n",
    "print('Alpha de Lasso : {}' .format(lassocv.alpha_))\n",
    "\n",
    "elasticnetcv = ElasticNetCV(cv = 5)\n",
    "elasticnetcv.fit(X_train, y_train)\n",
    "print('Alpha de EN: {}' .format(elasticnetcv.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos los modelos con los parámetros encontrados arriba\n",
    "\n",
    "lr = LinearRegression()\n",
    "ridge_reg = Ridge(normalize = True)\n",
    "ridge_reg.set_params(alpha = ridgecv.alpha_)\n",
    "lasso_reg = Lasso(normalize = True)\n",
    "lasso_reg.set_params(alpha = lassocv.alpha_)\n",
    "elasticNet_reg = ElasticNet()\n",
    "elasticNet_reg.set_params(alpha = elasticnetcv.alpha_, l1_ratio = elasticnetcv.l1_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora evaluamos y comparamos\n",
    "mnames = ['Linear Reg', 'Ridge', 'Lasso', 'Elastic Net']\n",
    "models = [lr, ridge_reg, lasso_reg, elasticNet_reg]\n",
    "\n",
    "R_squared_test = []\n",
    "RMSE_test = []\n",
    "R_squared_train = []\n",
    "RMSE_train = []\n",
    "\n",
    "\n",
    "# Funcion que evalua R^2 y RMSE en el train set y training set\n",
    "def performance(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    r2_test = metrics.r2_score(y_test, prediction)\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_test, prediction))\n",
    "    plt.figure(figsize = (10,6))\n",
    "    sns.distplot(y_test, color = 'darkturquoise', kde = False)\n",
    "    sns.distplot(prediction, color = 'goldenrod', kde = False)\n",
    "    plt.legend(labels = ['Actual', 'Predicted'])\n",
    "    prediction = model.predict(X_train)\n",
    "    r2_train = metrics.r2_score(y_train, prediction)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_train, prediction))\n",
    "    return r2_test, r2_train, rmse_test, rmse_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for model in models:\n",
    "    r2_test, r2_train, rmse_test, rmse_train = performance(model, X_train, y_train)\n",
    "    R_squared_test.append(r2_test)\n",
    "    RMSE_test.append(rmse_test)\n",
    "    R_squared_train.append(r2_train)\n",
    "    RMSE_train.append(rmse_train)\n",
    "    plt.title(mnames[i])\n",
    "    i=i+1\n",
    "    \n",
    "comparison = pd.DataFrame({'R2 test':R_squared_test,'RMSE test':RMSE_test, \n",
    "                           'R2 train':R_squared_train,'RMSE train':RMSE_train}, index = mnames) \n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos la regresión Ridge como mejor modelo respecto a R^2 y RMSE y guardamos las predicciones\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = testID\n",
    "predictions = ridge_reg.predict(test)\n",
    "submission['SalePrice'] = np.exp(predictions)\n",
    "submission.head()\n",
    "submission.to_csv('submission1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
